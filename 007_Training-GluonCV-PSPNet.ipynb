{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenImage Challenge 2019\n",
    "\n",
    "## training pspnet in gluoncv\n",
    "\n",
    "files (N is [0-9A-F]):\n",
    "\n",
    "BASE_DIR/classes-segmentation.txt   …download from https://storage.googleapis.com/openimages/v5/classes-segmentation.txt\n",
    "\n",
    "BASE_DIR/train-images-N/*.jpg   …training image from s3://open-images-dataset/tar/train_N.tar.gz\n",
    "\n",
    "BASE_DIR/mask-images-N/*.png   …mask image from https://storage.googleapis.com/openimages/v5/train-masks/train-masks-N.zip\n",
    "\n",
    "TEST_DIR/*.jpg   …test image for prediction\n",
    "\n",
    "temporary directory:\n",
    "\n",
    "TEMP_DIR/join-masks-N/\n",
    "TEMP_DIR/output-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DIR = '../'\n",
    "BASE_DIR = '../'\n",
    "TEST_DIR = BASE_DIR+'/test-images'\n",
    "with open(BASE_DIR+\"classes-segmentation.txt\") as f:\n",
    "    CLASSES = [c.strip() for c in f.readlines()]\n",
    "CLASSES = [\"__background__\"] + CLASSES\n",
    "NUM_CLASS = len(CLASSES)\n",
    "CLOP_SIZE = 480\n",
    "BASE_SIZE = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "NUM_WORKERS = 2\n",
    "NUM_EPOCHS = 1\n",
    "NUM_GPUS = 1\n",
    "USING_SPLITS = [\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(TEMP_DIR):\n",
    "    os.mkdir(TEMP_DIR)\n",
    "    os.mkdir(TEMP_DIR+\"join-masks-N/\")\n",
    "    os.mkdir(TEMP_DIR+\"output-images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mask_filepart_classname(name):\n",
    "    if name.startswith(\"m\"):\n",
    "        return \"/m/\" + name[1:]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def _create_resize_image(img, ismask=False, tosize=None):\n",
    "    long_side_size = BASE_SIZE * 2\n",
    "    if img.height < img.width:\n",
    "        scale = img.width / long_side_size\n",
    "        size = (long_side_size, max(BASE_SIZE,math.ceil(img.height / scale)))\n",
    "    else:\n",
    "        scale = img.height / long_side_size\n",
    "        size = (max(BASE_SIZE,math.ceil(img.width / scale)), long_side_size)\n",
    "    return img.resize(size if tosize is None else tosize, Image.NEAREST if ismask else Image.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_openimage2019_mask(split_name):\n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    img_folder = os.path.join(BASE_DIR, 'train-images-'+split_name)\n",
    "    mask_folder = os.path.join(BASE_DIR, 'mask-images-'+split_name)\n",
    "    join_folder = os.path.join(TEMP_DIR, 'join-masks-'+split_name)\n",
    "    image_mask = {}\n",
    "    for filename in tqdm(os.listdir(mask_folder)):\n",
    "        basename, _ = os.path.splitext(filename)\n",
    "        maskname = basename.split(\"_\")\n",
    "        if filename.endswith(\".png\"):\n",
    "            imgpath = os.path.join(img_folder, filename)\n",
    "            imagename = maskname[0] + '.jpg'\n",
    "            imagepath = os.path.join(img_folder, imagename)\n",
    "            if os.path.isfile(imagepath):\n",
    "                if imagepath not in image_mask:\n",
    "                    image_mask[imagename] = [filename]\n",
    "                else:\n",
    "                    image_mask[imagename].append(filename)\n",
    "            else:\n",
    "                print('cannot find the image:', imagepath)\n",
    "\n",
    "    for imagename, masknames in tqdm(image_mask.items()):\n",
    "        imgpath = os.path.join(img_folder, imagename)\n",
    "        img = _create_resize_image(Image.open(imgpath)).convert('RGB')\n",
    "        mask = np.zeros((img.height,img.width), dtype=np.int32)\n",
    "        for filename in masknames:\n",
    "            basename, _ = os.path.splitext(filename)\n",
    "            maskname = basename.split(\"_\")\n",
    "            maskpath = os.path.join(mask_folder, filename)\n",
    "            maskflag = _create_resize_image(Image.open(maskpath), ismask=True, tosize=(img.width,img.height)).convert('1')\n",
    "            maskclass = _mask_filepart_classname(maskname[1])\n",
    "            if maskclass in CLASSES:\n",
    "                mask[maskflag] = CLASSES.index(maskclass)\n",
    "\n",
    "        basename, _ = os.path.splitext(imagename)\n",
    "        joinpath = os.path.join(join_folder, basename)\n",
    "        np.save(joinpath, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d92320c0034d86b5eea4ec9e434435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd16189d4be64b519ed4df545e2f001a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for z in USING_SPLITS:\n",
    "    _make_openimage2019_mask(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.segbase import SegmentationDataset\n",
    "import random\n",
    "class OpenImage2019Segmentation(SegmentationDataset):\n",
    "    def __init__(self, splits=USING_SPLITS, **kwargs):\n",
    "        super(OpenImage2019Segmentation, self).__init__(BASE_DIR, split='train', mode=None, transform=None, **kwargs)\n",
    "        self.images, self.masks = [], []\n",
    "        for split in splits:\n",
    "            image, mask = _get_openimage2019_pairs(split)\n",
    "            self.images.extend(image)\n",
    "            self.masks.extend(mask)\n",
    "            \n",
    "    def __transform(self, img, mask):\n",
    "        # random mirror\n",
    "        if random.random() < 0.5:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            mask = mask[:, ::-1]\n",
    "        img, mask = self._img_transform(img), self._mask_transform(mask)\n",
    "        return img, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = _create_resize_image(Image.open(self.images[index])).convert('RGB')\n",
    "        cx = random.randint(0, img.width - CLOP_SIZE)\n",
    "        cy = random.randint(0, img.height - CLOP_SIZE)\n",
    "        mask = np.load(self.masks[index])\n",
    "        img, mask = self.__transform(img, mask)\n",
    "        return img[cy:cy+CLOP_SIZE,cx:cx+CLOP_SIZE,:].transpose((2,0,1)), mask[cy:cy+CLOP_SIZE,cx:cx+CLOP_SIZE]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return CLASSES\n",
    "\n",
    "    @property\n",
    "    def pred_offset(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "def _get_openimage2019_pairs(split_name):\n",
    "    img_paths = []\n",
    "    join_paths = []\n",
    "    img_folder = os.path.join(BASE_DIR, 'train-images-'+split_name)\n",
    "    join_folder = os.path.join(TEMP_DIR, 'join-masks-'+split_name)\n",
    "    for filename in os.listdir(img_folder):\n",
    "        basename, _ = os.path.splitext(filename)\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            imgpath = os.path.join(img_folder, filename)\n",
    "            joinname = basename + '.npy'\n",
    "            joinpath = os.path.join(join_folder, joinname)\n",
    "            if os.path.isfile(joinpath):\n",
    "                img_paths.append(imgpath)\n",
    "                join_paths.append(joinpath)\n",
    "            else:\n",
    "                print('cannot find the mask:', maskpath)\n",
    "\n",
    "    return img_paths, join_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import gluoncv\n",
    "from gluoncv.loss import *\n",
    "from gluoncv.utils import LRScheduler\n",
    "from gluoncv.model_zoo.segbase import *\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils.parallel import *\n",
    "from gluoncv.data import get_segmentation_dataset\n",
    "from gluoncv.model_zoo.pspnet import PSPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self):\n",
    "        ctx_list = [mx.gpu(i) for i in range(NUM_GPUS)]\n",
    "        trainset = OpenImage2019Segmentation()\n",
    "        self.train_data = gluon.data.DataLoader(\n",
    "            trainset, BATCH_SIZE, shuffle=True, last_batch='rollover', num_workers=NUM_WORKERS)\n",
    "        \n",
    "        model = PSPNet(NUM_CLASS, backbone='resnet50', pretrained_base=True, ctx=ctx_list)\n",
    "        model.cast(\"float16\")\n",
    "        \n",
    "        self.net = DataParallelModel(model, ctx_list)\n",
    "\n",
    "        criterion = MixSoftmaxCrossEntropyLoss(aux=True, mixup=False, aux_weight=0.2)\n",
    "        self.criterion = DataParallelCriterion(criterion, ctx_list, False)\n",
    "        \n",
    "        self.lr_scheduler = LRScheduler(mode='poly', base_lr=1e-3,\n",
    "                                        nepochs=NUM_EPOCHS,\n",
    "                                        iters_per_epoch=len(self.train_data),\n",
    "                                        power=0.9)\n",
    "        kv = mx.kv.create('device')\n",
    "        optimizer_params = {'lr_scheduler': self.lr_scheduler,\n",
    "                            'wd':0.0001,\n",
    "                            'momentum': 0.9,\n",
    "                            'learning_rate': 1e-3,\n",
    "                            'multi_precision': True\n",
    "                           }\n",
    "\n",
    "        self.optimizer = gluon.Trainer(self.net.module.collect_params(), 'sgd',\n",
    "                                       optimizer_params, kvstore = kv)\n",
    "\n",
    "    def training(self, epoch):\n",
    "        tbar = tqdm(self.train_data)\n",
    "        train_loss = 0.0\n",
    "        alpha = 0.2\n",
    "        for i, (data, target) in enumerate(tbar):\n",
    "            with autograd.record(True):\n",
    "                outputs = self.net(data.astype(\"float16\", copy=False))\n",
    "                losses = self.criterion(outputs, target)\n",
    "                mx.nd.waitall()\n",
    "                autograd.backward(losses)\n",
    "            self.optimizer.step(BATCH_SIZE)\n",
    "            for loss in losses:\n",
    "                train_loss += np.mean(loss.asnumpy()) / len(losses)\n",
    "            tbar.set_description('Epoch %d, training loss %.3f'%\\\n",
    "                (epoch, train_loss/(i+1)))\n",
    "            mx.nd.waitall()\n",
    "\n",
    "        return self.net.module\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.crop_size 480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48598cc282a3415ba83a22eb053af03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    net = trainer.training(epoch)\n",
    "    net.save_parameters(\"checkpoint_%d\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\"encode_binary_mask expects a binary mask, received dtype == %s\" % mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\"encode_binary_mask expects a 2d mask, received shape == %s\" % mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cca516cae9462897c10cd91525b6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = [filename for filename in os.listdir(TEST_DIR)]\n",
    "\n",
    "output_folder = os.path.join(TEMP_DIR, 'output-images')\n",
    "\n",
    "for filename in tqdm(test_images):\n",
    "    test_filename = os.path.join(TEST_DIR, filename)\n",
    "    basename, _ = os.path.splitext(filename)\n",
    "    org_img = Image.open(test_filename)\n",
    "    img = _create_resize_image(org_img).convert('RGB')\n",
    "    data = np.array(img).transpose((2,0,1))\n",
    "    indata = np.zeros((4,3,CLOP_SIZE,CLOP_SIZE), dtype=np.float16)\n",
    "    indata[0] = data[:,0:CLOP_SIZE,0:CLOP_SIZE]\n",
    "    indata[1] = data[:,data.shape[1]-CLOP_SIZE:data.shape[1],0:CLOP_SIZE]\n",
    "    indata[2] = data[:,0:CLOP_SIZE,data.shape[2]-CLOP_SIZE:data.shape[2]]\n",
    "    indata[3] = data[:,data.shape[1]-CLOP_SIZE:data.shape[1],data.shape[2]-CLOP_SIZE:data.shape[2]]\n",
    "    with mx.Context(mx.gpu()):  \n",
    "        indata = mx.nd.array(indata).astype(\"float16\")\n",
    "    out = net(indata)\n",
    "    outdata = np.zeros((NUM_CLASS,img.height,img.width))\n",
    "    outdata[:,0:CLOP_SIZE,0:CLOP_SIZE] = out[0].asnumpy()[0]\n",
    "    outdata[:,data.shape[1]-CLOP_SIZE:data.shape[1],0:CLOP_SIZE] = out[0].asnumpy()[1]\n",
    "    outdata[:,0:CLOP_SIZE,data.shape[2]-CLOP_SIZE:data.shape[2]] = out[0].asnumpy()[2]\n",
    "    outdata[:,data.shape[1]-CLOP_SIZE:data.shape[1],data.shape[2]-CLOP_SIZE:data.shape[2]] = out[0].asnumpy()[3]\n",
    "    outputpath = os.path.join(output_folder, basename)\n",
    "    np.save(outputpath, outdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802aecf492284a94935f65320aa82980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "empty_submission_df = pd.DataFrame({\"ImageID\":[filename.split(\".\")[0] for filename in os.listdir(TEST_DIR)]})\n",
    "#empty_submission_df = pd.read_csv(\"../input/open-images-2019-instance-segmentation/sample_empty_submission.csv\")\n",
    "ImageID_list = []\n",
    "ImageWidth_list = []\n",
    "ImageHeight_list = []\n",
    "PredictionString_list = []\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "for num, row in tqdm(empty_submission_df.iterrows(), total=len(empty_submission_df)):\n",
    "    filename = row[\"ImageID\"] + \".jpg\"\n",
    "    test_filename = os.path.join(TEST_DIR, filename)\n",
    "    org_img = Image.open(test_filename)\n",
    "    \n",
    "    filename = row[\"ImageID\"] + \".npy\"\n",
    "    outputpath = os.path.join(output_folder, filename)\n",
    "    output = np.load(outputpath)\n",
    "    img_out = output.argmax(axis=0)\n",
    "    \n",
    "    PredictionString = \"\"\n",
    "        \n",
    "    for i in range(1,NUM_CLASS,1):        \n",
    "        class_id = i\n",
    "        confidence = 1.0\n",
    "        \n",
    "        pred_mask = (img_out == i)\n",
    "        if pred_mask.sum() == 0:\n",
    "            continue\n",
    "        bin_img = output[i,:,:][pred_mask]\n",
    "        confidence = sigmoid(bin_img.mean())\n",
    "        \n",
    "        pred_mask = Image.fromarray(pred_mask.astype(np.uint8))\n",
    "        pred_mask_sized = pred_mask.resize((org_img.width,org_img.height), Image.NEAREST)\n",
    "        pred_mask_sized = np.array(pred_mask_sized) != 0\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            encoded_mask = encode_binary_mask(pred_mask_sized)\n",
    "            encoded_label = CLASSES[i]\n",
    "\n",
    "            PredictionString += encoded_label \n",
    "            PredictionString += \" \"\n",
    "            PredictionString += str(confidence)\n",
    "            PredictionString += \" \"\n",
    "            PredictionString += encoded_mask.decode()\n",
    "            PredictionString += \" \"\n",
    "        \n",
    "    ImageID_list.append(row[\"ImageID\"])\n",
    "    ImageWidth_list.append(org_img.width)\n",
    "    ImageHeight_list.append(org_img.height)\n",
    "    PredictionString_list.append(PredictionString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"ImageID\":ImageID_list,\n",
    "                      \"ImageWidth\":ImageWidth_list,\n",
    "                      \"ImageHeight\":ImageHeight_list,\n",
    "                      \"PredictionString\":PredictionString_list\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a806afcdc63693e3</td>\n",
       "      <td>1600</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a806afcdc63693e9</td>\n",
       "      <td>1600</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a806afcdc63693e1</td>\n",
       "      <td>1600</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a806afcdc63693e2</td>\n",
       "      <td>1600</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  ImageWidth  ImageHeight PredictionString\n",
       "0  a806afcdc63693e3        1600         1200                 \n",
       "1  a806afcdc63693e9        1600         1200                 \n",
       "2  a806afcdc63693e1        1600         1200                 \n",
       "3  a806afcdc63693e2        1600         1200                 "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"submission007.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
